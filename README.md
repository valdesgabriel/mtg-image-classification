# mtg-image-classification						Gabriel Valdes
Magic the Gathering Token Image Classification - Ironhack Final Project


Objective: Build a convolutional neural network to distinguish between two classes of Magic the Gathering images: play cards vs. token cards.

Introduction: Magic the Gathering (MTG) is a popular fantasy-based trading card game produced by Wizards of the Coast. Since 1993, Magic the Gathering has printed over 25,000 cards. Beginning in 2003, Magic the Gathering began printing a new card type called “Tokens”. Traditional “Play cards” are used to construct decks and play games; these cards are mostly called spells in-game and must be cast by paying an in-game cost (mana). Conversely, tokens are not spells and are not cast; they are only created by effects of spells and represent temporary game pieces.

Business Case: Recently hired at startup online retailer for MTG as data scientist. The business is buying as many cards as possible in bulk from eBay and similar platforms. In the thousands of cards purchased, many will be tokens which are not as highly valued as they are not used to construct decks. The business intends to scan the newly purchased cards and has enlisted me to create a classification model to be able to tell what in their stock is a play card versus a token. 

Approach & Execution
1. Gathering data: In the Juptyer notebook ‘Webscrape_Card_Images’ located in this repo is the code I used to web scrape images from an MTG search engine called Scryfall. The code mainly uses Python libraries BeautifulSoup to iteratively scrape the HTML code of multiple webpages of search results from Scryfall, urllib to open the scraped image URL in my computer’s memory and save a local file and os library to organize the data into folders based on their classes. The code in its current state in the notebook creates a new directory with multiple subfolders and asks for user inputs regarding how many pages the user would like to scrape for each class of card. WARNING: running this code will save card images directly to your computer. 
2. Fixing Data Imbalance with Digital Augmentation: After the scraping I had about 700 token images and over 2100 play card images (76% imbalance). To fix this imbalance and to mimic real-world scenarios like varying card condition and scan quality, I applied digital augmentation via the Tensorflow and keras libraries. I applied two different sets of random augmentation to each token image and kept the original, which tripled the number of records I had in the training set. For the play cards, I applied augmentation to only a handful of records. 
3. Building and fitting the CNN: My CNN model is built on 4 blocks of convolutional, pooling, dropout and normalization layers, before model is flattened and compiled. Since it is a binary classification problem, the dense/output layer is defined as 1 unit. I fit the model with 100 epochs which took about 3 or 4 hours with my limited PC set up. But when it was done, I ran predictions against my test data set and my model achieved 99% accuracy. I then reintroduced the biasedness back into my training set and fit my model once again and was surprised to see that it performed just as well on making predictions (98%). The code of each of these exercises (including the data augmentation step) is located in the ‘ImageClassification_CNN_Model’ and ‘ImageClassification_CNN_Model-Imbalanced’ notebooks in the repo. 
4. Transfer Learning: Next, I wanted to see how some of the pre-defined models, ResNet50 and VGG16, would do with my data. Because these models are highly regarded, I was anticipating great results, and they delivered. With just 1 epoch, the VGG16 model was returning a 99% accuracy score and the ResNet50 with 5 epochs close to 90%. Due to high computational costs and time, it would take to continue to run these models, I was satisfied with these results. 
5. Conspiracy, Scheme and Phenomena: The last step of my project involved a new web scraping exercise saving images of different card types called Conspiracy, Scheme and Phenomena (also found on ‘Webscrape_Card_Images’ notebook). I built a function take an input from a user to randomly select an image from the collection of scraped cards and then (in the ‘ImageClassification_ResNet_VGG16_NewPredict_Func’ notebook) each model is  put to the test to try to classify the card as a play card. 

